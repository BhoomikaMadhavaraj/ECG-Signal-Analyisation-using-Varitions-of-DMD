{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LIBRARY IMPORT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os, random\n",
    "\n",
    "from sklearn import model_selection                                  \n",
    "from sklearn.model_selection import train_test_split      \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler      # Scaling\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# getting methods for confusion matrix, F1 score, Accuracy Score\n",
    "from sklearn import metrics                                          \n",
    "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score,classification_report,roc_curve,auc,average_precision_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression     # For logistic Regression\n",
    "from sklearn.naive_bayes import GaussianNB              # For Naive Bayes classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier      # For K-NN Classifier\n",
    "from sklearn.svm import SVC                             # For support vector machine based classifier\n",
    "from sklearn.tree import DecisionTreeClassifier         # For Decision tree\n",
    "\n",
    "# for ensemble\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#from xgboost import XGBClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **FUNCTION DEFINITIONS**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **CONFUSION MATRIX PLOT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, yhat):\n",
    "    cm = confusion_matrix(y_test, yhat)\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax=ax, fmt='g', cmap=plt.cm.Blues, cbar=False);\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    ax.set_title('Confusion Matrix', size=8); \n",
    "    ax.xaxis.set_ticklabels(['Healthy', 'Diseased']); ax.yaxis.set_ticklabels(['Healthy', 'Diseased'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **LOGISTIC REGRESSION MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Logistic Regression\n",
    "def LoR(X_tr,Y_tr,X_te,Y_te):\n",
    "  lr = LogisticRegression(random_state=42)\n",
    "  lr.fit(X_tr,Y_tr)\n",
    "  lr_y_pred = lr.predict(X_te)\n",
    "\n",
    "  # Confusion Matrix for the Logistic Regression Model\n",
    "  plot_confusion_matrix(Y_te,lr_y_pred)\n",
    "\n",
    "  # Classification Report for the Logistic Regression Model\n",
    "  print(\"Classification Report : Logistic Regression\")\n",
    "  classRep = classification_report(Y_te, lr_y_pred, digits=2)\n",
    "  print(classRep)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **KNN MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "def KNN(X_train,Y_train,X_test,Y_test):\n",
    "  # creating odd list of K for KNN\n",
    "  kvalue = list(range(1,40,2))\n",
    "\n",
    "  # creating empty list for accuracy odd different value of K\n",
    "  acc = []\n",
    "\n",
    "  # perform accuracy metrics for values from different k values\n",
    "  for k in kvalue:\n",
    "      knn = KNeighborsClassifier(n_neighbors=k)\n",
    "      knn.fit(X_train, Y_train)\n",
    "      # predict \n",
    "      y_pred = knn.predict(X_test)\n",
    "      # evaluate accuracy\n",
    "      accuracy = accuracy_score(Y_test, y_pred)\n",
    "      acc.append(accuracy)\n",
    "\n",
    "  # determining best k\n",
    "  bestk = kvalue[acc.index(max(acc))]\n",
    "  print(\"The optimal number of neighbors is %d\" % bestk)\n",
    "  plt.plot(kvalue,acc)\n",
    "\n",
    "  # instantiate learning model (here k = 1)\n",
    "  knn = KNeighborsClassifier(n_neighbors = bestk, weights = 'uniform', metric='euclidean')\n",
    "\n",
    "  # fitting the model\n",
    "  knn.fit(X_train, Y_train)\n",
    "\n",
    "  # predict the response\n",
    "  knn_y_pred = knn.predict(X_test)\n",
    "\n",
    "  # Confusion Matrix for the K-nearest neighbors Model\n",
    "  plot_confusion_matrix(Y_test,knn_y_pred)\n",
    "\n",
    "  # Classification Report for the K-nearest neighbors Model\n",
    "  print(\"Classification Report : K-nearest neighbors\")\n",
    "  classRep = classification_report(Y_test, knn_y_pred, digits=2)\n",
    "  print(classRep)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **NAIVE BAYES MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "def NB(X_tr,Y_tr,X_te,Y_te):\n",
    "  # naive bayes\n",
    "  nb = GaussianNB()\n",
    "  nb.fit(X_tr , Y_tr)\n",
    "\n",
    "  # predict the response\n",
    "  nb_y_pred = nb.predict(X_te)\n",
    "\n",
    "  # Confusion Matrix for the Naive Bayes\n",
    "  plot_confusion_matrix(Y_te,nb_y_pred)\n",
    "\n",
    "  # Classification Report for the Naive Bayes Model\n",
    "  print(\"Classification Report : Naive Bayes\")\n",
    "  classRep = classification_report(Y_te, nb_y_pred, digits=2)\n",
    "  print(classRep)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **DECISION TREE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "def DT(X_tr,Y_tr,X_te,Y_te):\n",
    "  # Decison Tree\n",
    "  dt = DecisionTreeClassifier(random_state=42)\n",
    "  dt.fit(X_tr , Y_tr)\n",
    "\n",
    "  # predict the response\n",
    "  dt_y_pred = dt.predict(X_te)\n",
    "\n",
    "  # Confusion Matrix for the Decision Tree\n",
    "  plot_confusion_matrix(Y_te,dt_y_pred)\n",
    "\n",
    "  # Classification Report for the Decision Tree Model\n",
    "  print(\"Classification Report : Decision Tree\")\n",
    "  classRep = classification_report(Y_te, dt_y_pred, digits=2)\n",
    "  print(classRep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SVM MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "def svm(X_tr,Y_tr,X_te,Y_te):\n",
    "  # Normally, C = 1 and gamma = 'scale' are default values\n",
    "  # C controls how wide the margin will be with respect to how many misclassification we are allowing\n",
    "  # C is increasing --> reduce the size of the margin and fewer misclassification and vice versa\n",
    "  param_grid = [\n",
    "      {'C': [0.5, 1,  5, 10,  100],\n",
    "      'gamma': ['scale', 0.5, 1, 0.1, 0.01, 0.001],\n",
    "      'kernel': ['rbf', 'linear', 'poly', 'sigmoid']},\n",
    "  ]\n",
    "\n",
    "  optimal_params = GridSearchCV(SVC(),\n",
    "                              param_grid,\n",
    "                              cv=5, #  taking 10-fold as in k-fold cross validation\n",
    "                              scoring='accuracy', \n",
    "                              verbose=0,\n",
    "                              n_jobs=-1)\n",
    "\n",
    "  optimal_params.fit(X_tr, Y_tr)\n",
    "  print(optimal_params.best_params_)\n",
    "\n",
    "  #svm\n",
    "  C = optimal_params.best_params_['C']\n",
    "  gamma = optimal_params.best_params_['gamma']\n",
    "  kernel = optimal_params.best_params_['kernel']\n",
    "\n",
    "  svm = SVC(C=C, gamma=gamma, kernel=kernel)\n",
    "  svm.fit(X_tr,Y_tr)\n",
    "\n",
    "  # predict the response\n",
    "  svm_y_pred = svm.predict(X_te)\n",
    "\n",
    "  # Confusion Matrix for the Support Vector Machine Model\n",
    "  plot_confusion_matrix(Y_te,svm_y_pred)\n",
    "\n",
    "  # Classification Report for the Support Vector Machine Model\n",
    "  print(\"Classification Report : Support Vector Machine\")\n",
    "  classRep = classification_report(Y_te, svm_y_pred, digits=2)\n",
    "  print(classRep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **ENSEMBLE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble stacking\n",
    "def Ensemble(X_tr,Y_tr,X_te,Y_te):\n",
    "  level0 = list()\n",
    "  level0.append(('lr', LogisticRegression(random_state=42)))\n",
    "  level0.append(('knn', KNeighborsClassifier(n_neighbors = 1, weights = 'uniform', metric='euclidean')))\n",
    "  level0.append(('cart', DecisionTreeClassifier(random_state=42)))\n",
    "  level0.append(('svm', SVC(C= 30, gamma= 0.125, kernel= 'rbf')))\n",
    "  level0.append(('bayes', GaussianNB()))\n",
    "\n",
    "  # define meta learner model\n",
    "  level1 = LogisticRegression(random_state=42)\n",
    "\n",
    "  # define the stacking ensemble with cross validation of 5\n",
    "  Stack_model = StackingClassifier(estimators=level0, final_estimator=level1)\n",
    "\n",
    "  # predict the response\n",
    "  Stack_model.fit(X_tr, Y_tr)\n",
    "  prediction_Stack = Stack_model.predict(X_te)\n",
    "\n",
    "  # Confusion Matrix for the Stacking Model\n",
    "  plot_confusion_matrix(Y_te,prediction_Stack)\n",
    "\n",
    "  # Classification Report for the Stacking Model\n",
    "  print(\"Classification Report : Stacking\")\n",
    "  print(classification_report(Y_te, prediction_Stack, digits=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **RANDOM FOREST MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF(X_tr,Y_tr,X_te,Y_te):\n",
    "  \n",
    "  # Create the param grid\n",
    "  param_grid = {'n_estimators': [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)],# Number of trees in random forest\n",
    "                'max_depth': range(1,10),# Maximum number of levels in tree\n",
    "                'criterion':['gini','entropy'] }# measure the quality of a split\n",
    "\n",
    "  optimal_params = GridSearchCV(RandomForestClassifier(),\n",
    "                              param_grid,\n",
    "                              cv=10, # we are taking 10-fold as in k-fold cross validation\n",
    "                              scoring='accuracy', \n",
    "                              verbose=0,\n",
    "                              n_jobs=-1)\n",
    "\n",
    "  optimal_params.fit(X_tr, Y_tr)\n",
    "  print(optimal_params.best_params_)\n",
    "\n",
    "  criterion = optimal_params.best_params_['criterion']\n",
    "  max_depth = optimal_params.best_params_['max_depth']\n",
    "  n_estimators = optimal_params.best_params_['n_estimators']\n",
    "\n",
    "  #creating model of Random Forest\n",
    "  RandomForest = RandomForestClassifier(n_estimators = n_estimators, max_depth=max_depth, criterion=criterion,random_state=42)\n",
    "  RandomForest = RandomForest.fit(X_tr, Y_tr)\n",
    "\n",
    "  # predict the response\n",
    "  RandomForest_pred = RandomForest.predict(X_te)\n",
    "\n",
    "  # Confusion Matrix for the Random Forest Model\n",
    "  plot_confusion_matrix(Y_te,RandomForest_pred)\n",
    "\n",
    "  # Classification Report for the Randome Forest Model\n",
    "  print(\"Classification Report : Random Forest\")\n",
    "  print(classification_report(Y_te, RandomForest_pred, digits=2))  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **ADABOOST MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adaboost(X_tr,Y_tr,X_te,Y_te):\n",
    "  param_grid = {'n_estimators': [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]}\n",
    "  optimal_params = GridSearchCV(AdaBoostClassifier(),\n",
    "                              param_grid,\n",
    "                              cv=10, # we are taking 10-fold as in k-fold cross validation\n",
    "                              scoring='accuracy', \n",
    "                              verbose=0,\n",
    "                              n_jobs=-1)\n",
    "\n",
    "  optimal_params.fit(X_tr, Y_tr)\n",
    "  print(optimal_params.best_params_)\n",
    "  n_estimators = optimal_params.best_params_['n_estimators']\n",
    "  \n",
    "  #creating model of Adaptive Boosting\n",
    "  AdBs = AdaBoostClassifier( n_estimators= n_estimators)\n",
    "  AdBs  = AdBs.fit(X_tr, Y_tr)\n",
    "\n",
    "  # predict the response\n",
    "  AdBs_y_pred = AdBs.predict(X_te)\n",
    "\n",
    "  # Confusion Matrix for the Adaptive Boosting Model\n",
    "  plot_confusion_matrix(Y_te,AdBs_y_pred)\n",
    "\n",
    "  # Classification Report for the Adaptive Boosting Model\n",
    "  print(\"Classification Report : Adaptive Boosting\")\n",
    "  print(classification_report(Y_te, AdBs_y_pred, digits=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **XGBOOST MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost(X_tr,Y_tr,X_te,Y_te):\n",
    "  param_grid = {'n_estimators': [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]}\n",
    "  optimal_params = GridSearchCV(XGBClassifier(),\n",
    "                              param_grid,\n",
    "                              cv=10, # we are taking 10-fold as in k-fold cross validation\n",
    "                              scoring='accuracy', \n",
    "                              verbose=0,\n",
    "                              n_jobs=-1)\n",
    "\n",
    "  optimal_params.fit(X_tr, Y_tr)\n",
    "  print(optimal_params.best_params_)\n",
    "  n_estimators = optimal_params.best_params_['n_estimators']\n",
    "  xgBs =XGBClassifier(n_estimators= n_estimators)\n",
    "  xgBs  = xgBs.fit(X_tr, Y_tr)\n",
    "\n",
    "  # predict the response\n",
    "  xgBs_y_pred = xgBs.predict(X_te)\n",
    "\n",
    "  # Confusion Matrix for the Adaptive Boosting Model\n",
    "  plot_confusion_matrix(Y_te,xgBs_y_pred)\n",
    "\n",
    "  # Classification Report for the Adaptive Boosting Model\n",
    "  print(\"Classification Report : XG Boosting\")\n",
    "  print(classification_report(Y_te, xgBs_y_pred, digits=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SPLITTING & TRAINING**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **LOADING THE FEATURES AND SPLITTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_D = pd.read_csv('/home/senume/Project/MIS/mis-ECG_analysis_DMD/FEATURE_EXTRACTION/HODMD Paper/Features_Beat_Bundle branch block.csv')\n",
    "DATA_H = pd.read_csv('/home/senume/Project/MIS/mis-ECG_analysis_DMD/FEATURE_EXTRACTION/HODMD Paper/Features_Beat_Health Control.csv')\n",
    "\n",
    "DATA_D = DATA_D.dropna()\n",
    "DATA_H = DATA_H.dropna()\n",
    "\n",
    "DATA_D_Label_Shape = DATA_D.shape[0]\n",
    "DATA_D_Label = np.ones((DATA_D_Label_Shape)).tolist()\n",
    "DATA_D.insert(len(DATA_D.columns),\"Label\", DATA_D_Label)\n",
    "\n",
    "DATA_H_Label_Shape = DATA_H.shape[0]\n",
    "DATA_H_Label = np.zeros((DATA_H_Label_Shape)).tolist()\n",
    "DATA_H.insert(len(DATA_H.columns),\"Label\", DATA_H_Label)\n",
    "\n",
    "DATASET = pd.concat([DATA_H, DATA_D], ignore_index= True)\n",
    "X = DATASET.drop([\"name\", \"Label\"], axis =1)\n",
    "Y = DATASET[\"Label\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify= Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **TRAINING MODEL WITH CONFUSION MATRIX PLOT OUTPUT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LoR(X_tr=X_train, Y_tr=Y_train, X_te=X_test, Y_te=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB(X_tr=X_train, Y_tr=Y_train, X_te=X_test, Y_te=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT(X_tr=X_train, Y_tr=Y_train, X_te=X_test, Y_te=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ensemble(X_tr=X_train, Y_tr=Y_train, X_te=X_test, Y_te=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF(X_tr=X_train, Y_tr=Y_train, X_te=X_test, Y_te=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adaboost(X_tr=X_train, Y_tr=Y_train, X_te=X_test, Y_te=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost(X_tr=X_train, Y_tr=Y_train, X_te=X_test, Y_te=Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mis-ECG_analysis_DMD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52963b587970739f8bf0ef077359689988f9acab5854b35f2ef3fa01603820cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
